# Fake-News-Detection-CLF04
# D√©tection de Fake News - Projet FCC

**√âtude Comparative ML Classique vs Deep Learning pour la D√©tection de Fausses Nouvelles**

![Python](https://img.shields.io/badge/Python-3.11-blue)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-orange)
![Scikit-learn](https://img.shields.io/badge/Scikit--learn-1.5.2-green)
![Statut](https://img.shields.io/badge/Statut-Projet%20Acad√©mique-yellow)

---
## Ressources Principales
- Lien de la pr√©sentation : https://www.canva.com/design/DAHA30ihx2A/VUNYcR4X5F3GEYKT5rXcyQ/view?utm_content=DAHA30ihx2A&utm_campaign=designshare&utm_medium=link2&utm_source=uniquelinks&utlId=h3218f27538

- Lien vers le Dashboard : https://fcc-fake-news-detector-v2-2mn9kgrp73hiqqywkkmxth.streamlit.app/


## Table des Mati√®res

- [Vue d'Ensemble](#vue-densemble)
- [Architecture](#architecture)
- [Mod√®les √âvalu√©s](#mod√®les-√©valu√©s)
- [R√©sultats de Performance](#r√©sultats-de-performance)
- [Stack Technologique](#stack-technologique)
- [Structure du Projet](#structure-du-projet)
- [Installation](#installation)
- [Utilisation](#utilisation)
- [Application Web](#application-web)
- [Limitations et Analyse Critique](#limitations-et-analyse-critique)
- [Contact](#contact)

---

## Vue d'Ensemble

Projet acad√©mique d√©velopp√© dans le cadre d'un cours de **Natural Language Processing** pour la Federal Communications Commission. L'objectif est de comparer les approches de Machine Learning classique et Deep Learning pour la d√©tection automatique de fausses nouvelles, avec un focus sur les articles annon√ßant des catastrophes fictives.

### Points Cl√©s

- **Approche comparative** : √âvaluation de 6 mod√®les (4 ML classiques + 2 DL)
- **Optimisation** : GridSearchCV pour hyperparam√®tres des mod√®les classiques
- **Dataset** : 32,456 articles (Kaggle Fake News)
- **Meilleure performance** : BiLSTM avec 99.99% d'accuracy
- **Livrables** : Notebooks de recherche + Application web d√©ploy√©e

### Contexte Acad√©mique

**Institution** : Federal Communications Commission  
**Cours** : Natural Language Processing  
**Type** : Projet de fin de semestre avec pr√©sentation  
**Ann√©e** : 2024-2025

---

## Architecture

Le projet se compose de deux √©l√©ments distincts :

### 1. Pipeline de Recherche (Notebooks)

```
Exploration des donn√©es ‚Üí Pr√©traitement NLP ‚Üí Mod√®les ML Classiques (Baseline)
                                           ‚Üì
                              Optimisation Hyperparam√®tres (GridSearchCV)
                                           ‚Üì
                                    Mod√®les Deep Learning
                                           ‚Üì
                              √âvaluation Comparative Finale
```

### 2. Application Web (Microservices)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Utilisateur    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Frontend (Streamlit)      ‚îÇ
‚îÇ  - Interface utilisateur   ‚îÇ
‚îÇ  - Support multilingue     ‚îÇ
‚îÇ  - Visualisations          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ HTTP POST/JSON
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Backend (Flask API)       ‚îÇ
‚îÇ  - Pr√©traitement NLP       ‚îÇ
‚îÇ  - Inf√©rence mod√®le        ‚îÇ
‚îÇ  - Endpoint /predict       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Composant | Technologie | H√©bergement |
|-----------|-------------|-------------|
| Frontend | Streamlit 1.29 | Streamlit Cloud |
| Backend | Flask 3.0 + Gunicorn | Render.com |
| Communication | HTTP POST/JSON | - |

---

## Mod√®les √âvalu√©s

### ML Classique (Repr√©sentation TF-IDF)

| Mod√®le | Description | Use Case |
|--------|-------------|----------|
| **Linear SVM** | Support Vector Machine lin√©aire | Classification haute dimension |
| **Random Forest** | Ensemble de 100 arbres de d√©cision | Robustesse et performance |
| **Logistic Regression** | R√©gression logistique | Baseline interpr√©table |
| **Naive Bayes** | Classificateur probabiliste | R√©f√©rence rapide |

**Configuration TF-IDF** :
- Vocabulaire : 10000 features
- N-grammes : (1, 2) - unigrammes et bigrammes
- Fr√©quence document : min=1, max=0.8

### Optimisation des Hyperparam√®tres

Tous les mod√®les classiques ont √©t√© optimis√©s via **GridSearchCV** avec validation crois√©e (5-fold) :

| Mod√®le | Hyperparam√®tres Optimaux |
|--------|--------------------------|
| **Linear SVM** | `C=1.0, loss='squared_hinge'` |
| **Random Forest** | `max_depth=None, min_samples_split=2, n_estimators=200` |
| **Logistic Regression** | `C=10.0, penalty='l2', solver='lbfgs'` |
| **Naive Bayes** | `alpha=0.1` |

### Deep Learning (Word Embeddings)

#### CNN (Convolutional Neural Network)

```
Embedding(10000, 100) ‚Üí Conv1D(128, kernel=5) ‚Üí GlobalMaxPooling
‚Üí Dense(128) + Dropout(0.5) ‚Üí Dense(64) + Dropout(0.3)
‚Üí Dense(1, sigmoid)
```

**Hyperparam√®tres** :
- Learning rate : 2e-5
- Batch size : 32
- Optimizer : Adam

#### BiLSTM (Bidirectional LSTM)

```
Embedding(10000, 100) ‚Üí Bidirectional(LSTM(64))
‚Üí Attention Layer ‚Üí Dense(128) + Dropout(0.5)
‚Üí Dense(1, sigmoid)
```

---

## R√©sultats de Performance

### Classement Complet des Mod√®les

| Rang | Mod√®le | Type | Accuracy | Precision | Recall | F1-Score |
|------|--------|------|----------|-----------|--------|----------|
| ü•á | **BiLSTM** | Deep Learning | **99.99%** | 99.99% | 99.99% | 99.99% |
| ü•à | **Random Forest (Optimis√©)** | ML Classique | **99.72%** | 99.69% | 99.79% | 99.74% |
| ü•â | **Random Forest (Baseline)** | ML Classique | **99.68%** | 99.55% | 99.86% | 99.71% |
| 4 | **Linear SVM (Optimis√©)** | ML Classique | **99.64%** | 99.67% | 99.67% | 99.67% |
| 5 | **Linear SVM (Baseline)** | ML Classique | **99.60%** | 99.62% | 99.65% | 99.63% |
| 6 | **Logistic Regression (Optimis√©)** | ML Classique | **99.48%** | 99.48% | 99.58% | 99.53% |
| 7 | **Logistic Regression (Baseline)** | ML Classique | **99.03%** | 98.87% | 99.36% | 99.11% |
| 8 | **CNN** | Deep Learning | **98.91%** | 98.92% | 99.10% | 99.01% |
| 9 | **Naive Bayes (Optimis√©)** | ML Classique | **96.04%** | 97.03% | 95.71% | 96.37% |
| 10 | **Naive Bayes (Baseline)** | ML Classique | **95.72%** | 96.55% | 95.61% | 96.08% |

### Impact de l'Optimisation sur les Mod√®les Classiques

| Mod√®le | Baseline | Optimis√© | Am√©lioration |
|--------|----------|----------|--------------|
| **Random Forest** | 99.68% | 99.72% | **+0.04%** |
| **Linear SVM** | 99.60% | 99.64% | **+0.04%** |
| **Logistic Regression** | 99.03% | 99.48% | **+0.45%** |
| **Naive Bayes** | 95.72% | 96.04% | **+0.32%** |

**Observation cl√©** : L'optimisation via GridSearchCV a am√©lior√© les performances de **tous les mod√®les classiques**, avec un gain particuli√®rement significatif pour la R√©gression Logistique (+0.45%).

### Statistiques du Dataset

| Cat√©gorie | Quantit√© | Pourcentage |
|-----------|----------|-------------|
| **Total articles** | 32,456 | 100% |
| **Ensemble d'entra√Ænement** | 22,719 | 70% |
| **Ensemble de validation** | 4,869 | 15% |
| **Ensemble de test** | 4,868 | 15% |
| **Articles FAKE** | 23,481 | 72.3% |
| **Articles REAL** | 8,975 | 27.7% |

### Matrice de Confusion (BiLSTM - Meilleur Mod√®le)

```
                Pr√©diction
            REAL    FAKE
R√©el REAL   2182      0
     FAKE      4   5592
```

**Interpr√©tation** :
- Vrais Positifs : 2,182 articles r√©els correctement identifi√©s
- Vrais N√©gatifs : 5,592 fake news correctement d√©tect√©es
- Faux Positifs : 0 articles r√©els class√©s comme fake
- Faux N√©gatifs : 4 fake news manqu√©es (taux d'erreur : 0.05%)

---

## Stack Technologique

### Recherche et Mod√©lisation

| Cat√©gorie | Technologies |
|-----------|--------------|
| **Data Science** | Pandas 2.1.4, NumPy 1.24.3 |
| **NLP** | NLTK 3.8.1 (tokenisation, lemmatisation, stopwords) |
| **ML Classique** | Scikit-learn 1.5.2 (SVM, RF, LR, NB, TF-IDF, GridSearchCV) |
| **Deep Learning** | TensorFlow 2.15.0, Keras 2.15.0 |
| **Visualisation** | Matplotlib 3.8.2, Seaborn 0.13.0, WordCloud 1.9.3 |

### Application Web (Dashboard)

| Composant | Technologies |
|-----------|--------------|
| **Backend** | Flask 3.0.0, Gunicorn 21.2.0, flask-cors 4.0.0 |
| **Frontend** | Streamlit 1.29.0, Plotly 5.18.0 |
| **Traitement Fichiers** | PyPDF2 3.0.1, python-docx 1.1.0, openpyxl 3.1.2 |
| **Support Multilingue** | deep-translator 1.11.4, langdetect 1.0.9 |
| **D√©ploiement** | Render.com (backend), Streamlit Cloud (frontend) |

---

## Structure du Projet

```
fcc-fake-news-detection/
‚îÇ
‚îú‚îÄ‚îÄ notebooks/                        # Pipeline de recherche
‚îÇ   ‚îú‚îÄ‚îÄ fnd_01_exploration.ipynb     # EDA et statistiques
‚îÇ   ‚îú‚îÄ‚îÄ fnd_02_processing.ipynb      # Pr√©traitement NLP
‚îÇ   ‚îú‚îÄ‚îÄ fnd_03_ml_classique.ipynb    # SVM, RF, LR, NB (baseline)
‚îÇ   ‚îú‚îÄ‚îÄ fnd_04_optimisation.ipynb    # GridSearchCV et optimisation
‚îÇ   ‚îú‚îÄ‚îÄ fnd_05_cnn.ipynb             # Mod√®le CNN
‚îÇ   ‚îú‚îÄ‚îÄ fnd_06_bilstm.ipynb          # Mod√®le BiLSTM
‚îÇ   ‚îî‚îÄ‚îÄ fnd_07_evaluation.ipynb      # Comparaison finale
‚îÇ
‚îú‚îÄ‚îÄ models/                           # Mod√®les entra√Æn√©s
‚îÇ   ‚îú‚îÄ‚îÄ classical/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear_svm.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ linear_svm_optimized.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ random_forest.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ random_forest_optimized.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logistic_regression.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ logistic_regression_optimized.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ naive_bayes_optimized.pkl
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ tfidf_vectorizer.pkl
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ classical_models_results.csv
‚îÇ   ‚îî‚îÄ‚îÄ deep/
‚îÇ       ‚îú‚îÄ‚îÄ cnn_model.h5
‚îÇ       ‚îú‚îÄ‚îÄ bilstm_model.h5
‚îÇ       ‚îú‚îÄ‚îÄ keras_tokenizer.pkl
‚îÇ       ‚îú‚îÄ‚îÄ cnn_metrics.json
‚îÇ       ‚îî‚îÄ‚îÄ bilstm_metrics.json
‚îÇ
‚îú‚îÄ‚îÄ reports/                          # Rapports et r√©sultats
‚îÇ   ‚îî‚îÄ‚îÄ results/
‚îÇ       ‚îî‚îÄ‚îÄ model_performance_YYYYMMDD_HHMMSS.xlsx
‚îÇ
‚îú‚îÄ‚îÄ backend/                          # API Flask
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ frontend/                         # Interface Streamlit
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ utils.py
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îÇ
‚îú‚îÄ‚îÄ data/                             # Donn√©es brutes
‚îÇ   ‚îú‚îÄ‚îÄ Fake.csv
‚îÇ   ‚îî‚îÄ‚îÄ True.csv
‚îÇ
‚îî‚îÄ‚îÄ README.md
```

---

## Installation

### Pr√©requis

- Python 3.11 ou sup√©rieur
- Git
- pip

### Configuration Locale

#### 1. Cloner le d√©p√¥t

```bash
git clone https://github.com/votre-username/fcc-fake-news-detection.git
cd fcc-fake-news-detection
```

#### 2. Cr√©er un environnement virtuel

**Windows** :
```bash
python -m venv venv
venv\Scripts\activate
```

**macOS/Linux** :
```bash
python3 -m venv venv
source venv/bin/activate
```

#### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

#### 4. T√©l√©charger les ressources NLTK

```bash
python -c "import nltk; nltk.download('stopwords'); nltk.download('wordnet')"
```

#### 5. Lancer Jupyter (pour les notebooks)

```bash
jupyter notebook
```

---

## Utilisation

### Pipeline de Recherche (Notebooks)

Les notebooks doivent √™tre ex√©cut√©s dans l'ordre :

1. **fnd_01_exploration.ipynb** : Analyse exploratoire des donn√©es
   - Distribution des classes
   - Statistiques textuelles
   - Visualisations (nuages de mots, histogrammes)

2. **fnd_02_processing.ipynb** : Pr√©traitement NLP
   - Nettoyage du texte
   - Tokenisation et lemmatisation
   - Suppression des stopwords
   - Division train/validation/test (70/15/15)

3. **fnd_03_ml_classique.ipynb** : Mod√®les ML classiques (Baseline)
   - Vectorisation TF-IDF
   - Entra√Ænement SVM, RF, LR, NB
   - √âvaluation sur ensemble de validation
   - Sauvegarde mod√®les (.pkl) et m√©triques (.csv)

4. **fnd_04_optimisation.ipynb** : Optimisation des hyperparam√®tres
   - GridSearchCV avec validation crois√©e (5-fold)
   - Recherche exhaustive sur grilles de param√®tres
   - R√©entra√Ænement avec meilleurs hyperparam√®tres
   - Sauvegarde mod√®les optimis√©s (*_optimized.pkl)

5. **fnd_05_cnn.ipynb** : Mod√®le CNN
   - Architecture convolutionnelle 1D
   - Entra√Ænement avec callbacks (EarlyStopping, ModelCheckpoint)
   - Sauvegarde mod√®le (.h5) et m√©triques (.json)

6. **fnd_06_bilstm.ipynb** : Mod√®le BiLSTM
   - Architecture LSTM bidirectionnelle
   - M√©canisme d'attention
   - Sauvegarde mod√®le et m√©triques

7. **fnd_07_evaluation.ipynb** : √âvaluation comparative
   - Chargement de tous les mod√®les (baseline + optimis√©s + DL)
   - Comparaison des performances
   - Visualisations comparatives
   - S√©lection du meilleur mod√®le

### Sauvegarde des Mod√®les

**ML Classiques** :
```python
import pickle

# Sauvegarder mod√®le
with open('models/classical/linear_svm_optimized.pkl', 'wb') as f:
    pickle.dump(svm_model, f)

# Sauvegarder vectorizer
with open('models/classical/tfidf_vectorizer.pkl', 'wb') as f:
    pickle.dump(vectorizer, f)
```

**Deep Learning** :
```python
# Sauvegarder mod√®le Keras
bilstm_model.save('models/deep/bilstm_model.h5')

# Sauvegarder m√©triques
import json
with open('models/deep/bilstm_metrics.json', 'w') as f:
    json.dump(bilstm_metrics, f, indent=4)
```

---

## Application Web

### D√©marrage Local

**Backend (API Flask)** :
```bash
cd backend
python app.py
# Disponible √† http://localhost:5000
```

**Frontend (Streamlit)** :
```bash
cd frontend
streamlit run app.py
# Disponible √† http://localhost:8501
```

### Fonctionnalit√©s

**M√©thodes d'entr√©e** :
- Saisie de texte direct
- Extraction depuis URL (HTML, PDF, DOCX)
- Upload de fichiers (TXT, PDF, DOCX, XLSX)

**Support multilingue** :
- D√©tection automatique de la langue
- Traduction vers l'anglais (5 langues support√©es)

**Visualisations** :
- Score de confiance (jauge 0-100%)
- Distribution des probabilit√©s (graphique en barres)
- Historique des analyses (timeline)

### API REST

**Endpoint de pr√©diction** :

```bash
POST /predict
Content-Type: application/json

{
  "text": "Votre texte d'article ici"
}
```

**R√©ponse** :

```json
{
  "prediction": 1,
  "label": "FAKE",
  "confidence": 0.8534,
  "probabilities": {
    "real": 0.1466,
    "fake": 0.8534
  }
}
```

**Exemple Python** :

```python
import requests

response = requests.post(
    "https://votre-api.onrender.com/predict",
    json={"text": "Breaking news: shocking discovery!"},
    timeout=60
)
result = response.json()
print(f"{result['label']} - Confiance: {result['confidence']:.2%}")
```

---

## Limitations et Analyse Critique

### S√©parabilit√© Artificielle du Dataset

Le dataset Kaggle pr√©sente un **biais structurel majeur** :

| Type d'article | Cat√©gories | Vocabulaire |
|----------------|-----------|-------------|
| **Articles REAL** | Politique am√©ricaine | Politicians, government, election |
| **Articles FAKE** | Sujets vari√©s | Shocking, truth, exposed, conspiracy |

**Cons√©quence** : Les mod√®les apprennent √† distinguer les **styles et sources** plut√¥t que la d√©sinformation intrins√®que.

### Impact sur les Performances

Les scores exceptionnels (>99%) refl√®tent cette s√©parabilit√© artificielle plut√¥t qu'une capacit√© de g√©n√©ralisation r√©elle.

**Points cl√©s** :
- ‚úÖ **BiLSTM atteint 99.99%** gr√¢ce √† sa capacit√© √† capturer les d√©pendances s√©quentielles
- ‚úÖ **L'optimisation am√©liore tous les mod√®les classiques** (gain moyen : +0.21%)
- ‚ö†Ô∏è **Ces r√©sultats ne garantissent pas** la performance sur des donn√©es en conditions r√©elles
- ‚ö†Ô∏è **Le dataset pr√©sente une s√©parabilit√© artificielle** par sujet et style

### Recommandations pour Am√©lioration

- Utiliser un dataset √©quilibr√© (m√™mes sujets pour FAKE et REAL)
- Int√©grer l'analyse des sources et m√©tadonn√©es
- Ajouter du fact-checking externe
- Tester sur des donn√©es en conditions r√©elles

---
**Liens** :
- Application web : [√Ä compl√©ter]
- API REST : [√Ä compl√©ter]

---

## Remerciements

- **Dataset** : Kaggle Fake News Competition
- **R√©f√©rences acad√©miques** : Roumeliotis et al. (2025) - Comparative study of CNNs, BERT, and GPT for fake news detection
- **Technologies** : TensorFlow, Scikit-learn, Streamlit, Flask
- **H√©bergement** : Render.com et Streamlit Cloud

---

**Projet acad√©mique - NLP Course 2024-2025**