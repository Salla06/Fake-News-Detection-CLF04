{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Fake News Detection - Phase 5: Optimisation et Ã‰valuation des ModÃ¨les Classiques\n",
        "\n",
        "### Objectifs de ce notebook\n",
        "\n",
        "**Objectif** : Optimiser les hyperparamÃ¨tres des modÃ¨les classiques via GridSearchCV, Ã©valuer leurs performances sur les donnÃ©es de test, sauvegarder les modÃ¨les optimisÃ©s et comparer avec les modÃ¨les non optimisÃ©s.\n",
        "\n",
        "**Contenu** :\n",
        "- Chargement des donnÃ©es preprocessÃ©es\n",
        "- Optimisation des hyperparamÃ¨tres (GridSearchCV)\n",
        "- Ã‰valuation sur les donnÃ©es de test\n",
        "- Sauvegarde des modÃ¨les (pickle) et performances (Excel)\n",
        "- Comparaison modÃ¨les optimisÃ©s vs non optimisÃ©s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.1 Importation des bibliothÃ¨ques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "ename": "ImportError",
          "evalue": "cannot import name '_promote' from 'scipy.spatial.transform._rotation' (c:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\scipy\\spatial\\transform\\_rotation.cp311-win_amd64.pyd)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatetime\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Machine Learning\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSearchCV\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msvm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LinearSVC\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\__init__.py:70\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# `_distributor_init` allows distributors to run custom init code.\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;66;03m# For instance, for the Windows wheel, this is used to pre-load the\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;66;03m# vcomp shared library runtime for OpenMP embedded in the sklearn/.libs\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __check_build, _distributor_init  \u001b[38;5;66;03m# noqa: E402 F401\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m clone  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions  \u001b[38;5;66;03m# noqa: E402\u001b[39;00m\n\u001b[0;32m     73\u001b[0m _submodules \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalibration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompose\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    112\u001b[0m ]\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m InconsistentVersionWarning\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_metadata_requests\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _MetadataRequester, _routing_enabled\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_missing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_pandas_na, is_scalar_nan\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_parameter_constraints\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\__init__.py:9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m metadata_routing\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_bunch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Bunch\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_chunking\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m gen_batches, gen_even_slices\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Make _safe_indexing importable from here for backward compat as this particular\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# helper is considered semi-private and typically very useful for third-party\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# libraries that want to comply with scikit-learn's estimator API. In particular,\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# _safe_indexing was included in our public API documentation despite the leading\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# `_` in its name.\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_indexing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _safe_indexing, resample, shuffle\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_chunking.py:11\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval, validate_params\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mchunk_generator\u001b[39m(gen, chunksize):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Chunk generator, ``gen`` into lists of length ``chunksize``. The last\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;124;03m    chunk may have a length less than ``chunksize``.\"\"\"\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:17\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m csr_matrix, issparse\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m config_context, get_config\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _is_arraylike_not_scalar\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mInvalidParameterError\u001b[39;00m(\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[0;32m     21\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Custom exception to be raised when the parameter of a class/method/function\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m    does not have a valid type or value.\u001b[39;00m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:24\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_config \u001b[38;5;28;01mas\u001b[39;00m _get_config\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexceptions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     20\u001b[0m     DataConversionWarning,\n\u001b[0;32m     21\u001b[0m     NotFittedError,\n\u001b[0;32m     22\u001b[0m     PositiveSpectrumWarning,\n\u001b[0;32m     23\u001b[0m )\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     25\u001b[0m     _asarray_with_order,\n\u001b[0;32m     26\u001b[0m     _convert_to_numpy,\n\u001b[0;32m     27\u001b[0m     _is_numpy_namespace,\n\u001b[0;32m     28\u001b[0m     _max_precision_float_dtype,\n\u001b[0;32m     29\u001b[0m     get_namespace,\n\u001b[0;32m     30\u001b[0m     get_namespace_and_device,\n\u001b[0;32m     31\u001b[0m )\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_pandas_df, is_pandas_df_or_series\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_isfinite\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FiniteStatus, cy_isfinite\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:20\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexternals\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marray_api_compat\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m numpy \u001b[38;5;28;01mas\u001b[39;00m np_compat\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_dataframe\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_df_or_series\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfixes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m parse_version\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# TODO: complete __all__\u001b[39;00m\n\u001b[0;32m     23\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpx\u001b[39m\u001b[38;5;124m\"\u001b[39m]  \u001b[38;5;66;03m# we import xpx here just to re-export it, need this to appease ruff\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\fixes.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinalg\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstats\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\scipy\\stats\\__init__.py:628\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03m.. _statsrefmanual:\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    623\u001b[0m \n\u001b[0;32m    624\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m  \u001b[38;5;66;03m# noqa: E501\u001b[39;00m\n\u001b[0;32m    626\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_warnings_errors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[0;32m    627\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[1;32m--> 628\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_stats_py\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m    629\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_variation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m variation\n\u001b[0;32m    630\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdistributions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py:40\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m array, asarray, ma\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m sparse\n\u001b[1;32m---> 40\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance_matrix\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moptimize\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m milp, LinearConstraint\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _get_nan, _rename_parameter, _contains_nan, np_vecdot\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\scipy\\spatial\\__init__.py:124\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ckdtree, kdtree, qhull\n\u001b[0;32m    122\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [s \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdir\u001b[39m() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m--> 124\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m distance, transform\n\u001b[0;32m    126\u001b[0m __all__ \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdistance\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransform\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PytestTester\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\scipy\\spatial\\transform\\__init__.py:21\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mSpatial Transformations (:mod:`scipy.spatial.transform`)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m========================================================\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;124;03m   RotationSpline\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rotation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rotation, Slerp\n\u001b[1;32m---> 21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rigid_transform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RigidTransform\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rotation_spline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RotationSpline\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# Deprecated namespaces, to be removed in v2.0.0\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\scipy\\spatial\\transform\\_rigid_transform.py:17\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_lib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_array_api\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     10\u001b[0m     array_namespace,\n\u001b[0;32m     11\u001b[0m     is_numpy,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     xp_capabilities,\n\u001b[0;32m     15\u001b[0m )\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Rotation\n\u001b[1;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rotation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _promote\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rigid_transform_cy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcython_backend\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspatial\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransform\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_rigid_transform_xp\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mxp_backend\u001b[39;00m\n",
            "\u001b[1;31mImportError\u001b[0m: cannot import name '_promote' from 'scipy.spatial.transform._rotation' (c:\\Users\\ndeye\\anaconda3\\Lib\\site-packages\\scipy\\spatial\\transform\\_rotation.cp311-win_amd64.pyd)"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle\n",
        "import warnings\n",
        "from datetime import datetime\n",
        "\n",
        "# Machine Learning\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# MÃ©triques\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, \n",
        "    f1_score, classification_report, confusion_matrix\n",
        ")\n",
        "\n",
        "# Visualisation\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"âœ“ BibliothÃ¨ques importÃ©es avec succÃ¨s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.2 Chargement des donnÃ©es"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Chargement des donnÃ©es preprocessÃ©es\n",
        "with open('data/X_train_tfidf.pkl', 'rb') as f:\n",
        "    X_train = pickle.load(f)\n",
        "\n",
        "with open('data/X_test_tfidf.pkl', 'rb') as f:\n",
        "    X_test = pickle.load(f)\n",
        "\n",
        "with open('data/y_train.pkl', 'rb') as f:\n",
        "    y_train = pickle.load(f)\n",
        "\n",
        "with open('data/y_test.pkl', 'rb') as f:\n",
        "    y_test = pickle.load(f)\n",
        "\n",
        "print(f\"Train shape: {X_train.shape}\")\n",
        "print(f\"Test shape: {X_test.shape}\")\n",
        "print(f\"Distribution des classes (train): {np.bincount(y_train)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.3 Chargement des modÃ¨les de base (non optimisÃ©s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Charger les rÃ©sultats des modÃ¨les non optimisÃ©s pour comparaison\n",
        "baseline_results = {}\n",
        "\n",
        "models_baseline = {\n",
        "    'LinearSVC': 'models/linear_svc_model.pkl',\n",
        "    'RandomForest': 'models/random_forest_model.pkl',\n",
        "    'NaiveBayes': 'models/naive_bayes_model.pkl',\n",
        "    'LogisticRegression': 'models/logistic_regression_model.pkl'\n",
        "}\n",
        "\n",
        "for name, path in models_baseline.items():\n",
        "    try:\n",
        "        with open(path, 'rb') as f:\n",
        "            model = pickle.load(f)\n",
        "        y_pred = model.predict(X_test)\n",
        "        baseline_results[name] = {\n",
        "            'accuracy': accuracy_score(y_test, y_pred),\n",
        "            'precision': precision_score(y_test, y_pred),\n",
        "            'recall': recall_score(y_test, y_pred),\n",
        "            'f1': f1_score(y_test, y_pred)\n",
        "        }\n",
        "    except FileNotFoundError:\n",
        "        print(f\"âš  ModÃ¨le {name} non trouvÃ©, sera ignorÃ© dans la comparaison\")\n",
        "\n",
        "print(\"âœ“ RÃ©sultats baseline chargÃ©s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.4 Optimisation des hyperparamÃ¨tres\n",
        "\n",
        "Utilisation de GridSearchCV avec validation croisÃ©e 5-fold pour trouver les meilleurs hyperparamÃ¨tres."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4.1 Linear SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Optimisation de Linear SVM...\")\n",
        "\n",
        "# Grille d'hyperparamÃ¨tres\n",
        "param_grid_svm = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'loss': ['hinge', 'squared_hinge'],\n",
        "    'max_iter': [1000, 2000]\n",
        "}\n",
        "\n",
        "# GridSearch\n",
        "grid_svm = GridSearchCV(\n",
        "    LinearSVC(random_state=42, dual='auto'),\n",
        "    param_grid_svm,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_svm.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nMeilleurs paramÃ¨tres: {grid_svm.best_params_}\")\n",
        "print(f\"Meilleur score CV: {grid_svm.best_score_:.4f}\")\n",
        "\n",
        "# Sauvegarde\n",
        "with open('models/linear_svc_optimized.pkl', 'wb') as f:\n",
        "    pickle.dump(grid_svm.best_estimator_, f)\n",
        "\n",
        "print(\"âœ“ ModÃ¨le sauvegardÃ©\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4.2 Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Optimisation de Random Forest...\")\n",
        "\n",
        "param_grid_rf = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [None, 10, 20],\n",
        "    'min_samples_split': [2, 5],\n",
        "    'min_samples_leaf': [1, 2]\n",
        "}\n",
        "\n",
        "grid_rf = GridSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_grid_rf,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_rf.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nMeilleurs paramÃ¨tres: {grid_rf.best_params_}\")\n",
        "print(f\"Meilleur score CV: {grid_rf.best_score_:.4f}\")\n",
        "\n",
        "with open('models/random_forest_optimized.pkl', 'wb') as f:\n",
        "    pickle.dump(grid_rf.best_estimator_, f)\n",
        "\n",
        "print(\"âœ“ ModÃ¨le sauvegardÃ©\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4.3 Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Optimisation de Naive Bayes...\")\n",
        "\n",
        "param_grid_nb = {\n",
        "    'alpha': [0.1, 0.5, 1.0, 2.0],\n",
        "    'fit_prior': [True, False]\n",
        "}\n",
        "\n",
        "grid_nb = GridSearchCV(\n",
        "    MultinomialNB(),\n",
        "    param_grid_nb,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_nb.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nMeilleurs paramÃ¨tres: {grid_nb.best_params_}\")\n",
        "print(f\"Meilleur score CV: {grid_nb.best_score_:.4f}\")\n",
        "\n",
        "with open('models/naive_bayes_optimized.pkl', 'wb') as f:\n",
        "    pickle.dump(grid_nb.best_estimator_, f)\n",
        "\n",
        "print(\"âœ“ ModÃ¨le sauvegardÃ©\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4.4 Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Optimisation de Logistic Regression...\")\n",
        "\n",
        "param_grid_lr = {\n",
        "    'C': [0.1, 1, 10],\n",
        "    'penalty': ['l2'],\n",
        "    'solver': ['lbfgs', 'liblinear'],\n",
        "    'max_iter': [1000, 2000]\n",
        "}\n",
        "\n",
        "grid_lr = GridSearchCV(\n",
        "    LogisticRegression(random_state=42),\n",
        "    param_grid_lr,\n",
        "    cv=5,\n",
        "    scoring='f1',\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid_lr.fit(X_train, y_train)\n",
        "\n",
        "print(f\"\\nMeilleurs paramÃ¨tres: {grid_lr.best_params_}\")\n",
        "print(f\"Meilleur score CV: {grid_lr.best_score_:.4f}\")\n",
        "\n",
        "with open('models/logistic_regression_optimized.pkl', 'wb') as f:\n",
        "    pickle.dump(grid_lr.best_estimator_, f)\n",
        "\n",
        "print(\"âœ“ ModÃ¨le sauvegardÃ©\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.5 Ã‰valuation sur les donnÃ©es de test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dictionnaire pour stocker les modÃ¨les optimisÃ©s\n",
        "optimized_models = {\n",
        "    'LinearSVC': grid_svm.best_estimator_,\n",
        "    'RandomForest': grid_rf.best_estimator_,\n",
        "    'NaiveBayes': grid_nb.best_estimator_,\n",
        "    'LogisticRegression': grid_lr.best_estimator_\n",
        "}\n",
        "\n",
        "# Ã‰valuation de chaque modÃ¨le\n",
        "optimized_results = {}\n",
        "\n",
        "for name, model in optimized_models.items():\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"Ã‰valuation: {name} (OptimisÃ©)\")\n",
        "    print('='*60)\n",
        "    \n",
        "    # PrÃ©dictions\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    # MÃ©triques\n",
        "    acc = accuracy_score(y_test, y_pred)\n",
        "    prec = precision_score(y_test, y_pred)\n",
        "    rec = recall_score(y_test, y_pred)\n",
        "    f1 = f1_score(y_test, y_pred)\n",
        "    \n",
        "    optimized_results[name] = {\n",
        "        'accuracy': acc,\n",
        "        'precision': prec,\n",
        "        'recall': rec,\n",
        "        'f1': f1,\n",
        "        'predictions': y_pred\n",
        "    }\n",
        "    \n",
        "    print(f\"Accuracy:  {acc:.4f}\")\n",
        "    print(f\"Precision: {prec:.4f}\")\n",
        "    print(f\"Recall:    {rec:.4f}\")\n",
        "    print(f\"F1-Score:  {f1:.4f}\")\n",
        "    \n",
        "    print(\"\\nRapport de classification:\")\n",
        "    print(classification_report(y_test, y_pred, \n",
        "                                target_names=['True News', 'Fake News']))\n",
        "\n",
        "print(\"\\nâœ“ Ã‰valuation terminÃ©e\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.6 Matrices de confusion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(14, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, (name, results) in enumerate(optimized_results.items()):\n",
        "    cm = confusion_matrix(y_test, results['predictions'])\n",
        "    \n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "                xticklabels=['True', 'Fake'],\n",
        "                yticklabels=['True', 'Fake'],\n",
        "                ax=axes[idx])\n",
        "    \n",
        "    axes[idx].set_title(f'{name} (OptimisÃ©)\\nF1-Score: {results[\"f1\"]:.4f}')\n",
        "    axes[idx].set_ylabel('Vraie Classe')\n",
        "    axes[idx].set_xlabel('Classe PrÃ©dite')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/confusion_matrices_optimized.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ Matrices de confusion sauvegardÃ©es\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.7 Comparaison modÃ¨les optimisÃ©s vs non optimisÃ©s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CrÃ©er un DataFrame de comparaison\n",
        "comparison_data = []\n",
        "\n",
        "for model_name in optimized_results.keys():\n",
        "    # Baseline\n",
        "    if model_name in baseline_results:\n",
        "        comparison_data.append({\n",
        "            'ModÃ¨le': model_name,\n",
        "            'Version': 'Baseline',\n",
        "            'Accuracy': baseline_results[model_name]['accuracy'],\n",
        "            'Precision': baseline_results[model_name]['precision'],\n",
        "            'Recall': baseline_results[model_name]['recall'],\n",
        "            'F1-Score': baseline_results[model_name]['f1']\n",
        "        })\n",
        "    \n",
        "    # OptimisÃ©\n",
        "    comparison_data.append({\n",
        "        'ModÃ¨le': model_name,\n",
        "        'Version': 'OptimisÃ©',\n",
        "        'Accuracy': optimized_results[model_name]['accuracy'],\n",
        "        'Precision': optimized_results[model_name]['precision'],\n",
        "        'Recall': optimized_results[model_name]['recall'],\n",
        "        'F1-Score': optimized_results[model_name]['f1']\n",
        "    })\n",
        "\n",
        "df_comparison = pd.DataFrame(comparison_data)\n",
        "print(\"\\nComparaison des performances:\")\n",
        "print(df_comparison.to_string(index=False))\n",
        "\n",
        "# Calcul des amÃ©liorations\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"AmÃ©liorations apportÃ©es par l'optimisation:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for model_name in optimized_results.keys():\n",
        "    if model_name in baseline_results:\n",
        "        f1_base = baseline_results[model_name]['f1']\n",
        "        f1_opt = optimized_results[model_name]['f1']\n",
        "        improvement = ((f1_opt - f1_base) / f1_base) * 100\n",
        "        \n",
        "        print(f\"\\n{model_name}:\")\n",
        "        print(f\"  F1 Baseline: {f1_base:.4f}\")\n",
        "        print(f\"  F1 OptimisÃ©: {f1_opt:.4f}\")\n",
        "        print(f\"  AmÃ©lioration: {improvement:+.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.8 Visualisation comparative"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graphique de comparaison\n",
        "metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score']\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "axes = axes.ravel()\n",
        "\n",
        "for idx, metric in enumerate(metrics):\n",
        "    df_metric = df_comparison.pivot(index='ModÃ¨le', columns='Version', values=metric)\n",
        "    \n",
        "    df_metric.plot(kind='bar', ax=axes[idx], width=0.8)\n",
        "    axes[idx].set_title(f'Comparaison: {metric}', fontsize=14, fontweight='bold')\n",
        "    axes[idx].set_ylabel(metric, fontsize=12)\n",
        "    axes[idx].set_xlabel('ModÃ¨le', fontsize=12)\n",
        "    axes[idx].legend(title='Version', fontsize=10)\n",
        "    axes[idx].grid(axis='y', alpha=0.3)\n",
        "    axes[idx].set_ylim([0.9, 1.0])  # Ajuster selon vos rÃ©sultats\n",
        "    \n",
        "    # Ajouter les valeurs sur les barres\n",
        "    for container in axes[idx].containers:\n",
        "        axes[idx].bar_label(container, fmt='%.4f', fontsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('figures/comparison_baseline_vs_optimized.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"âœ“ Graphiques de comparaison sauvegardÃ©s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.9 Identification du meilleur modÃ¨le"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Trouver le meilleur modÃ¨le parmi tous (baseline + optimisÃ©s)\n",
        "all_results = []\n",
        "\n",
        "for model_name in optimized_results.keys():\n",
        "    if model_name in baseline_results:\n",
        "        all_results.append({\n",
        "            'ModÃ¨le': f\"{model_name} (Baseline)\",\n",
        "            'F1-Score': baseline_results[model_name]['f1'],\n",
        "            'Accuracy': baseline_results[model_name]['accuracy']\n",
        "        })\n",
        "    \n",
        "    all_results.append({\n",
        "        'ModÃ¨le': f\"{model_name} (OptimisÃ©)\",\n",
        "        'F1-Score': optimized_results[model_name]['f1'],\n",
        "        'Accuracy': optimized_results[model_name]['accuracy']\n",
        "    })\n",
        "\n",
        "df_all = pd.DataFrame(all_results).sort_values('F1-Score', ascending=False)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"CLASSEMENT COMPLET DES MODÃˆLES (par F1-Score)\")\n",
        "print(\"=\"*60)\n",
        "print(df_all.to_string(index=False))\n",
        "\n",
        "best_model = df_all.iloc[0]\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ðŸ† MEILLEUR MODÃˆLE\")\n",
        "print(\"=\"*60)\n",
        "print(f\"ModÃ¨le: {best_model['ModÃ¨le']}\")\n",
        "print(f\"F1-Score: {best_model['F1-Score']:.4f}\")\n",
        "print(f\"Accuracy: {best_model['Accuracy']:.4f}\")\n",
        "print(\"=\"*60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.10 Sauvegarde des rÃ©sultats dans Excel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CrÃ©er un fichier Excel avec plusieurs feuilles\n",
        "timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
        "excel_file = f'results/model_performance_{timestamp}.xlsx'\n",
        "\n",
        "with pd.ExcelWriter(excel_file, engine='openpyxl') as writer:\n",
        "    # Feuille 1: Comparaison complÃ¨te\n",
        "    df_comparison.to_excel(writer, sheet_name='Comparaison', index=False)\n",
        "    \n",
        "    # Feuille 2: Classement\n",
        "    df_all.to_excel(writer, sheet_name='Classement', index=False)\n",
        "    \n",
        "    # Feuille 3: HyperparamÃ¨tres optimaux\n",
        "    hyperparam_data = [\n",
        "        {'ModÃ¨le': 'LinearSVC', 'ParamÃ¨tres': str(grid_svm.best_params_)},\n",
        "        {'ModÃ¨le': 'RandomForest', 'ParamÃ¨tres': str(grid_rf.best_params_)},\n",
        "        {'ModÃ¨le': 'NaiveBayes', 'ParamÃ¨tres': str(grid_nb.best_params_)},\n",
        "        {'ModÃ¨le': 'LogisticRegression', 'ParamÃ¨tres': str(grid_lr.best_params_)}\n",
        "    ]\n",
        "    df_hyperparam = pd.DataFrame(hyperparam_data)\n",
        "    df_hyperparam.to_excel(writer, sheet_name='HyperparamÃ¨tres', index=False)\n",
        "    \n",
        "    # Feuille 4: Meilleur modÃ¨le\n",
        "    best_summary = pd.DataFrame([{\n",
        "        'Meilleur ModÃ¨le': best_model['ModÃ¨le'],\n",
        "        'F1-Score': best_model['F1-Score'],\n",
        "        'Accuracy': best_model['Accuracy'],\n",
        "        'Date': datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
        "    }])\n",
        "    best_summary.to_excel(writer, sheet_name='Meilleur ModÃ¨le', index=False)\n",
        "\n",
        "print(f\"\\nâœ“ RÃ©sultats sauvegardÃ©s dans: {excel_file}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4.11 RÃ©sumÃ© final"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"RÃ‰SUMÃ‰ DE L'OPTIMISATION\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nðŸ“Š Fichiers gÃ©nÃ©rÃ©s:\")\n",
        "print(\"  - ModÃ¨les optimisÃ©s: models/*_optimized.pkl\")\n",
        "print(f\"  - Performances: {excel_file}\")\n",
        "print(\"  - Visualisations: figures/*.png\")\n",
        "\n",
        "print(\"\\nðŸŽ¯ Principaux rÃ©sultats:\")\n",
        "print(f\"  - Meilleur modÃ¨le: {best_model['ModÃ¨le']}\")\n",
        "print(f\"  - Performance: F1={best_model['F1-Score']:.4f}, Acc={best_model['Accuracy']:.4f}\")\n",
        "\n",
        "# Compter les amÃ©liorations\n",
        "improvements = 0\n",
        "for model_name in optimized_results.keys():\n",
        "    if model_name in baseline_results:\n",
        "        if optimized_results[model_name]['f1'] > baseline_results[model_name]['f1']:\n",
        "            improvements += 1\n",
        "\n",
        "print(f\"\\nâœ¨ {improvements}/{len(optimized_results)} modÃ¨les amÃ©liorÃ©s par l'optimisation\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"âœ“ OPTIMISATION TERMINÃ‰E AVEC SUCCÃˆS\")\n",
        "print(\"=\"*80)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
